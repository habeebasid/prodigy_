{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # We'll be storing our data as numpy arrays\nimport os # For handling directories\nfrom PIL import Image # For handling the images\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg # Plotting","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-05T09:55:42.017625Z","iopub.execute_input":"2023-11-05T09:55:42.018484Z","iopub.status.idle":"2023-11-05T09:55:42.022977Z","shell.execute_reply.started":"2023-11-05T09:55:42.018449Z","shell.execute_reply":"2023-11-05T09:55:42.021919Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%%time\nlookup = dict()\nreverselookup = dict()\ncount = 0\nfor j in os.listdir('../input/leapgestrecog/leapGestRecog/00/'):\n    if not j.startswith('.'): # If running this code locally, this is to \n                              # ensure you aren't reading in hidden folders\n        lookup[j] = count\n        reverselookup[count] = j\n        count = count + 1\nlookup","metadata":{"execution":{"iopub.status.busy":"2023-11-05T09:55:46.077727Z","iopub.execute_input":"2023-11-05T09:55:46.078074Z","iopub.status.idle":"2023-11-05T09:55:46.096830Z","shell.execute_reply.started":"2023-11-05T09:55:46.078043Z","shell.execute_reply":"2023-11-05T09:55:46.095952Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"CPU times: user 2.03 ms, sys: 288 Âµs, total: 2.31 ms\nWall time: 10.3 ms\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'02_l': 0,\n '04_fist_moved': 1,\n '09_c': 2,\n '10_down': 3,\n '06_index': 4,\n '08_palm_moved': 5,\n '07_ok': 6,\n '05_thumb': 7,\n '01_palm': 8,\n '03_fist': 9}"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nx_data = []\ny_data = []\ndatacount = 0 # We'll use this to tally how many images are in our dataset\nfor i in range(0, 10): # Loop over the ten top-level folders\n    for j in os.listdir('../input/leapgestrecog/leapGestRecog/0' + str(i) + '/'):\n        if not j.startswith('.'): # Again avoid hidden folders\n            count = 0 # To tally images of a given gesture\n            for k in os.listdir('../input/leapgestrecog/leapGestRecog/0' + \n                                str(i) + '/' + j + '/'):\n                                # Loop over the images\n                img = Image.open('../input/leapgestrecog/leapGestRecog/0' + \n                                 str(i) + '/' + j + '/' + k).convert('L')\n                                # Read in and convert to greyscale\n                img = img.resize((320, 120))\n                arr = np.array(img)\n                x_data.append(arr) \n                count = count + 1\n            y_values = np.full((count, 1), lookup[j]) \n            y_data.append(y_values)\n            datacount = datacount + count\nx_data = np.array(x_data, dtype = 'float32')\ny_data = np.array(y_data)\ny_data = y_data.reshape(datacount, 1) # Reshape to be the correct size","metadata":{"execution":{"iopub.status.busy":"2023-11-05T09:55:48.117799Z","iopub.execute_input":"2023-11-05T09:55:48.118612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom random import randint\nfor i in range(0, 10):\n    plt.imshow(x_data[i*200 , :, :])\n    plt.title(reverselookup[y_data[i*200 ,0]])\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.utils import to_categorical\ny_data = to_categorical(y_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = x_data.reshape((datacount, 120, 320, 1))\nx_data /= 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2)\nx_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nfrom keras import models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=models.Sequential()\nmodel.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(120, 320,1))) \nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu')) \nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=5, batch_size=64, verbose=1, validation_data=(x_validate, y_validate))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\nprint(\"Accuracy:\" + str(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Model weights and model\nmodel.save_weights('gesture_model_weights.h5')\nmodel.save(\"gesture_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow import image\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.save('gesture_recognition_model.h5')\n\n\n# model.save_weights('gesture_recognition_model_weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n\nloaded_model = load_model('gesture_recognition_model.h5')\n\n#loaded_model.load_weights('gesture_recognition_model_weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import image\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_test = []\n\ndatacount = 0 # We'll use this to tally how many images are in our dataset\nfolder_path = '/kaggle/input/test2-img/'\n\nfor filename in os.listdir(folder_path):\n    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n       \n        img_path = os.path.join(folder_path, filename)\n        count = 0 # To tally images of a given gesture\n\n        \n        img = Image.open(img_path).convert('L')  # Convert to grayscale\n        img = img.resize((320, 120))\n        arr = np.array(img)\n        t_test.append(arr)\n        count = count + 1\n        \n    datacount = datacount + count\nt_test = np.array(t_test, dtype = 'float32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, 5):\n    plt.imshow(t_test[i , :, :])\n    plt.title(i)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npredicted_gestures = []\n\nfor i in range(t_test.shape[0]):\n    img_show = t_test[i].reshape(120,320)  \n    \n    img2 = img_show.reshape(1, 120, 320, 1)  \n    img2 /= 255.0  \n    \n    predictions = loaded_model.predict(img2)\n \n    predicted_class = np.argmax(predictions)\n    predicted_gesture = reverselookup[predicted_class]\n    predicted_gestures.append(predicted_gesture)\n    \n    plt.imshow(img_show, cmap='gray') \n    \n    plt.title(f\"Image {i + 1}: {predicted_gesture}\")\n    plt.show()\nprint(\"Predicted Gestures:\", predicted_gestures)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n \nfolder_path = '/kaggle/input/test2-img/'\n\n \npredicted_gestures = []\n \nfor filename in os.listdir(folder_path):\n    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n        \n        img_path = os.path.join(folder_path, filename)\n\n       \n        img = Image.open(img_path).convert('L')  # Convert to grayscale\n        img = img.resize((320, 120))\n        arr = np.array(img)\n        t_test = arr.reshape((1, 120, 320, 1))\n        t_test = t_test / 255.0\n        plt.imshow(arr, cmap='gray')\n\n   \n        predictions = loaded_model.predict(t_test)\n\n \n        predicted_class = np.argmax(predictions)\n        predicted_gesture = reverselookup[predicted_class]\n        predicted_gestures.append(predicted_gesture)\n\nprint(\"Predicted Gestures:\", predicted_gestures)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data.size, y_data.size, t_test.view","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}